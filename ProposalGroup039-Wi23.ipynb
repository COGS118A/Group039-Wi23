{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Pelé\n",
    "- Diego Maradonna\n",
    "- Johan Cruyff\n",
    "- Roberto Carlos\n",
    "- Franz Beckenbaur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We plan to experiement with the following dataset to achieve the goal of this project: Detecting Fraudulent Transactions In Cryotocurrencies Exchange. The potential dataset(s) are as follows:\n",
    "- [Ethereum Fraud Detection Dataset](https://www.kaggle.com/datasets/vagifa/ethereum-frauddetection-dataset?datasetId=1074447&sortBy=voteCounthttps://www.kaggle.com/datasets/vagifa/ethereum-frauddetection-dataset?datasetId=1074447&sortBy=voteCount)\n",
    "- [Elliptic Dataset](https://www.kaggle.com/datasets/ellipticco/elliptic-data-set)\n",
    "\n",
    "__Ethereum Fraud Detection Dataset:__\n",
    "\n",
    "This dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency.\n",
    "\n",
    "Each observation consists of the following features:\n",
    "- Index: the index number of a row\n",
    "- Address: the address of the ethereum account\n",
    "- FLAG: whether the transaction is fraud or not\n",
    "- Avg min between sent tnx: Average time between sent transactions for account in minutes\n",
    "- Avg_min_between_received_tnx: Average time between received transactions for account in minutes\n",
    "- Time_Diff_between_first_and_last(Mins): Time difference between the first and last transaction\n",
    "- Sent_tnx: Total number of sent normal transactions\n",
    "- Received_tnx: Total number of received normal transactions\n",
    "- Number_of_Created_Contracts: Total Number of created contract transactions\n",
    "- Unique_Received_From_Addresses: Total Unique addresses from which account received transactions\n",
    "- Unique_Sent_To_Addresses20: Total Unique addresses from which account sent transactions\n",
    "- Min_Value_Received: Minimum value in Ether ever received\n",
    "- Max_Value_Received: Maximum value in Ether ever received\n",
    "- Avg_Value_Received5Average value in Ether ever received\n",
    "- Min_Val_Sent: Minimum value of Ether ever sent\n",
    "- Max_Val_Sent: Maximum value of Ether ever sent\n",
    "- Avg_Val_Sent: Average value of Ether ever sent\n",
    "- Min_Value_Sent_To_Contract: Minimum value of Ether sent to a contract\n",
    "- Max_Value_Sent_To_Contract: Maximum value of Ether sent to a contract\n",
    "- Avg_Value_Sent_To_Contract: Average value of Ether sent to contracts\n",
    "- Total_Transactions(Including_Tnx_to_Create_Contract): Total number of transactions\n",
    "- Total_Ether_Sent:Total Ether sent for account address\n",
    "- Total_Ether_Received: Total Ether received for account address\n",
    "- Total_Ether_Sent_Contracts: Total Ether sent to Contract addresses\n",
    "- Total_Ether_Balance: Total Ether Balance following enacted transactions\n",
    "- Total_ERC20_Tnxs: Total number of ERC20 token transfer transactions\n",
    "- ERC20_Total_Ether_Received: Total ERC20 token received transactions in Ether\n",
    "- ERC20_Total_Ether_Sent: Total ERC20token sent transactions in Ether\n",
    "- ERC20_Total_Ether_Sent_Contract: Total ERC20 token transfer to other contracts in Ether\n",
    "- ERC20_Uniq_Sent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n",
    "- ERC20_Uniq_Rec_Addr: Number of ERC20 token transactions received from Unique addresses\n",
    "- ERC20_Uniq_Rec_Contract_Addr: Number of ERC20token transactions received from Unique contract addresses\n",
    "- ERC20_Avg_Time_Between_Sent_Tnx: Average time between ERC20 token sent transactions in minutes\n",
    "- ERC20_Avg_Time_Between_Rec_Tnx: Average time between ERC20 token received transactions in minutes\n",
    "- ERC20_Avg_Time_Between_Contract_Tnx: Average time ERC20 token between sent token transactions\n",
    "- ERC20_Min_Val_Rec: Minimum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20_Max_Val_Rec: Maximum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20_Avg_Val_Rec: Average value in Ether received from ERC20 token transactions for account\n",
    "- ERC20_Min_Val_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20_Max_Val_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20_Avg_Val_Sent: Average value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20_Uniq_Sent_Token_Name: Number of Unique ERC20 tokens transferred\n",
    "- ERC20_Uniq_Rec_Token_Name: Number of Unique ERC20 tokens received\n",
    "- ERC20_Most_Sent_Token_Type: Most sent token for account via ERC20 transaction\n",
    "- ERC20_Most_Rec_Token_Type: Most received token for account via ERC20 transactions\n",
    "\n",
    "The critical variables in this dataset are yet to be discovered - we will need to perform data inspection on this dataset to infer feature importance.\n",
    "\n",
    "We have inspected the above dataset and found out that the following changes are necessary:\n",
    "- The dataset has severe class imbalance (7662 Non-Fraud, 2179 Fraud), we'll need to resolve this with methods like SMOTE.\n",
    "- Replace missings of numerical variables with median\n",
    "- We will need to drop features with 0 variance since these features will not contribute in the performance of the model.\n",
    "- We also need to drop the group of highly correlated features since they won't bring significant additional information, but instead will increase complexity of the algorithm and demand in compute resource.\n",
    "- Discard features whose values are mostly 0's.\n",
    "- Normalize the features.\n",
    "\n",
    "__Elliptic Dataset:__\n",
    "\n",
    "The Elliptic Dataset is a graph network of Bitcoin transactions with handcrafted features. All features are constructed using only publicly available information.\n",
    "\n",
    "The dataset maps Bitcoin transactions to real entities in two categories:\n",
    "- *Licit:* exchanges, wallet providers, miners, licit services, etc.\n",
    "- *Ilicit:* scams, malware, terrorist, organization, ransomware, Ponzi shcemes, etc\n",
    "\n",
    "A given transaction is licit if the entity that generated it was licit.\n",
    "- *Nodes and Edges:* 203,769 node transactions and 234,355 directed edge payments flows. 2% (4,545) are ilicit (Class 1), 21% (42,019) are licit (Class 2)\n",
    "- *Features:* Each node has associated 166 features. 94 represent local information (timestep, number of inputs/outputs, transaction fee, output volume and aggregated figures) and 72 features represent aggregated features (obtained by aggregating transaction information such as maximum, minimum, standard deviation, correlation coefficients of neighbor transactions).\n",
    "- *Temporal Information:* A time step is associated with each node, representing an stimated of the time when the transaction is confirmed. There are 49 distinct timesteps evenly spaced with an interval of 2 weeks.\n",
    "\n",
    "As far as what are the critical valiables and how they are represented, we do not have a clear opinion on this yet since we have not perform sufficient exploration on the dataset to conclude what features may be of more importance in answering the problem statement. To justify this further, quoting from the dataset provider: *\"Due to intellectual property issues, we cannot provide an exact description of all the features in the dataset\"*. This makes it even harder to read columns from the dataset and infer their importance on answering the problem statement.\n",
    "\n",
    "At the time being, after small exploration on the data, there is only one minor change that we need to do on this dataset: change the column names to something more meaningful.\n",
    "\n",
    "In conclusion, with this dataset, our task is to classify the illicit and licit nodes in the graph (given a node in the graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "We propose a solution using a decision-tree ensemble algorithm, in particular the XGBoost algorithm. We hypothesise that this algorithm will work well on the dataset due to the fact that XGBoost is known to work well on such dataset, i.e: XGBoost is a popular algorithm for binary classification tasks. We can further strengthen this hypothesis by first running multiple ML algorithms on the dataset: logistic regression, decision trees, and random forests. We can determine which one performed best on the dataset via metrics such as precision, recall, and F1 score. Implementing XGBoost on this dataset is as simple as using the XGBoost library.\n",
    "\n",
    "Finally, we will compare this solution with the Light Gradient Boosting Machine (LGBM) approach proposed by Sarthak Et. al. in *\"LGBM: a machine learning approach for Ethereum fraud\n",
    "detection\"* which claims to show slightly better performance (98.60%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
